{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "데이터셋 및 파일 접근을 위한 os, ImageFolder, Image 등의 모듈과, 직접적 데이터 조작을 위한 모듈, 연산을 위한 알고리즘을 가진 모듈을 import.\n",
        "메인은 PyTorch 프레임워크 사용."
      ],
      "metadata": {
        "id": "oCbu87aKZR_C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJAi0py4Qvm-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import random_split\n",
        "from torch.utils.data import DataLoader, Dataset, Subset\n",
        "from torch.utils.data import SubsetRandomSampler\n",
        "from torchvision import datasets, transforms, models\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.utils import make_grid\n",
        "from pytorch_lightning import LightningModule\n",
        "from pytorch_lightning import Trainer\n",
        "import pytorch_lightning as pl\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "torchvision의 transforms 메소드로 사용할 이미지 데이터에 대한 전처리 파이프라인 틀을 잡아줌.\n",
        ": transforms.Compose() 메소드는 모든 이미지 데이터가 같은 전처리 과정을 거치게 함."
      ],
      "metadata": {
        "id": "PVkuY68AZxuf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform=transforms.Compose([\n",
        "    transforms.RandomRotation(10), # 랜덤하게 이미지 회전(10도) : 데이터 다양하게 변형하여 과적합 방지\n",
        "    transforms.RandomHorizontalFlip(), # 랜덤하게 이미지 좌우 뒤집기 : 위와 동일\n",
        "    transforms.Resize(224), # 이미지의 크기를 224 by 224 로 조정 : 일반적으로 이 크기를 사용\n",
        "    transforms.CenterCrop(224), # 이미지 중앙을 또 한 번 24 by 224 로 자름 : 중요 부분\n",
        "    transforms.ToTensor(), # 이미지를 텐서로 변환\n",
        "    transforms.Normalize( [0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225] ) # 이미지의 채널을 정규화\n",
        "])"
      ],
      "metadata": {
        "id": "bBLqZKRPZQt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터셋을 불러오고 이상이 없는지 확인하는 과정. 가공된 데이터 프레임을 새로 만듦."
      ],
      "metadata": {
        "id": "3REYzwgAcH55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체가 확인하는 코드\n",
        "\n",
        "data=pd.read_csv('/content/Train')\n",
        "print(len(data))\n",
        "class_names=sorted(data['label'].unique().tolist())\n",
        "print(class_names)\n",
        "print(len(class_names))\n",
        "N=list(range(len(class_names)))\n",
        "normal_mapping=dict(zip(class_names,N))\n",
        "reverse_mapping=dict(zip(N, class_names))\n",
        "data['label2']=data['label'].map(normal_mapping)\n",
        "dir0='/content/'\n",
        "data['path']=dir0+data['filename']\n",
        "display(data)"
      ],
      "metadata": {
        "id": "VCUBkOyIcHWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 함수는 데이터 프레임의 이미지 파일 경로와 레이블을 묶은 튜플을 원소로 가지는 리스트를 생성."
      ],
      "metadata": {
        "id": "-RDzSb6ddrd9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_path_label_list(df):\n",
        "    path_label_list= []\n",
        "    for _, row in df.iterrows():\n",
        "        path=row['path']\n",
        "        label=row['label2']\n",
        "        path_label_list.append((path,label))\n",
        "    return path_label_list\n",
        "\n",
        "# 확인\n",
        "#path_label=create_path_label_list(data)\n",
        "#print(path_label[0:3])"
      ],
      "metadata": {
        "id": "a9xNBunWdanx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 로더를 위한 클래스 하나를 만듦."
      ],
      "metadata": {
        "id": "Hjq8wBRjemf5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, path_label, transform=None): # 생성자\n",
        "        self.path_label = path_label # 방금 위에서 만든 함수의 반환\n",
        "        self.transform = transform # 아까 위에서 만든 전처리 파이프라인\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.path_label)\n",
        "\n",
        "    # 인덱스 사용해 이미지 파일 경로와 레이블 추출, 이미지에 전처리 과정을 적용\n",
        "    def __getitem__(self, idx):\n",
        "        path, label = self.path_label[idx]\n",
        "        img = Image.open(path).convert('RGB') # RGB : Channel=3\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label"
      ],
      "metadata": {
        "id": "zxwgmmrqel_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch Lightning은 PyTorch 간편화 라이브러리인데 이것을 사용해 이미지 데이터셋 로드 후 전처리를 진행."
      ],
      "metadata": {
        "id": "G2FfaYAZgHJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageDataset(pl.LightningDataModule):\n",
        "    def __init__(self, path_label, batch_size=32):\n",
        "        super().__init__()\n",
        "        self.path_label = path_label\n",
        "        self.batch_size = batch_size # 데이터 로더의 반환 배치 크기를 지정\n",
        "\n",
        "        # 전처리 파이프라인을 새롭게 정의\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "        ])\n",
        "\n",
        "    # 데이터 모듈을 설정하는 메소드, 데이터 로드 후 훈련용과 테스트용 데이터 분류\n",
        "    def setup(self, stage=None):\n",
        "        dataset = CustomDataset(self.path_label, self.transform)\n",
        "        dataset_size = len(dataset)\n",
        "        train_size = int(0.8 * dataset_size)\n",
        "        test_size = dataset_size - train_size\n",
        "\n",
        "        self.train_dataset = torch.utils.data.Subset(dataset, range(train_size))\n",
        "        self.test_dataset = torch.utils.data.Subset(dataset, range(train_size, dataset_size))\n",
        "\n",
        "    def __len__(self): # 데이터셋의 길이 반환(훈련 or 테스트)\n",
        "        if self.train_dataset is not None:\n",
        "            return len(self.train_dataset)\n",
        "        elif self.test_dataset is not None:\n",
        "            return len(self.test_dataset)\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "    # 인덱스를 사용해 하나의 샘플 데이터 반환(훈련 or 테스트)\n",
        "    def __getitem__(self, index):\n",
        "        if self.train_dataset is not None:\n",
        "            return self.train_dataset[index]\n",
        "        elif self.test_dataset is not None:\n",
        "            return self.test_dataset[index]\n",
        "        else:\n",
        "            raise IndexError(\"Index out of range. The dataset is empty.\")\n",
        "\n",
        "    def train_dataloader(self): # 훈련용\n",
        "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "    def val_dataloader(self): # 검증용\n",
        "        return DataLoader(self.test_dataset, batch_size=self.batch_size)\n",
        "\n",
        "    def test_dataloader(self): # 테스트용\n",
        "        return DataLoader(self.test_dataset, batch_size=self.batch_size)"
      ],
      "metadata": {
        "id": "53FNJP1YgHbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터셋을 훈련용과 테스트용으로 분리."
      ],
      "metadata": {
        "id": "jYPpeOJQi0yP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataModule(pl.LightningDataModule):\n",
        "\n",
        "    def __init__(self, transform=transform, batch_size=32):\n",
        "        super().__init__()\n",
        "        self.root_dir = \"/content/\"\n",
        "        self.transform = transform # 위와 동일\n",
        "        self.batch_size = batch_size # 위와 동일\n",
        "\n",
        "    # 데이터 모듈을 설정하는 메소드\n",
        "    def setup(self, stage=None):\n",
        "        dataset = datasets.ImageFolder(root=self.root_dir, transform=self.transform)\n",
        "        n_data = len(dataset)\n",
        "        n_train = int(0.8 * n_data)\n",
        "        n_test = n_data - n_train\n",
        "\n",
        "        train_dataset, test_dataset =  random_split(dataset, [n_train, n_test])\n",
        "\n",
        "        # 훈련용과 테스트용 데이터셋을 데이터 로더로 변환\n",
        "        self.train_dataset = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
        "        self.test_dataset = DataLoader(test_dataset, batch_size=self.batch_size)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return self.train_dataset\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return self.test_dataset"
      ],
      "metadata": {
        "id": "Y5pts3KHi1DJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN 모델인데 PyTorch Lightning을 사용하여 간단한 구현이 가능."
      ],
      "metadata": {
        "id": "sn_T53BOkn5K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvolutionalNetwork(LightningModule):\n",
        "\n",
        "    # 이미지 데이터는 이곳에서 2개의 합성곱층과 3개의 전결합층을 거쳐 출력됨\n",
        "    def __init__(self): # 중요한 생성자\n",
        "        super(ConvolutionalNetwork, self).__init__()\n",
        "\n",
        "        # 합성곱층은 2개\n",
        "        self.conv1 = nn.Conv2d(3, 6, 3, 1)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 3, 1)\n",
        "\n",
        "        # 실질적 전결합층은 3개, 각 메소드의 첫 인자는 이전 결과(출력)를 사용\n",
        "        self.fc1 = nn.Linear(16 * 54 * 54, 120) # 120개 뉴런\n",
        "        self.fc2 = nn.Linear(120, 84) # 84개 뉴런\n",
        "        self.fc3 = nn.Linear(84, 20) # 20개 뉴런\n",
        "        self.fc4 = nn.Linear(20, len(class_names)) # 여긴 softmax 함수 사용해 클래스 분류에 사용됨\n",
        "\n",
        "    # 순전파 메소드\n",
        "    def forward(self, X):\n",
        "        X = F.relu(self.conv1(X)) # 활성화 함수 : ReLu\n",
        "        X = F.max_pool2d(X, 2, 2)\n",
        "        X = F.relu(self.conv2(X))\n",
        "        X = F.max_pool2d(X, 2, 2)\n",
        "        X = X.view(-1, 16 * 54 * 54)\n",
        "        X = F.relu(self.fc1(X))\n",
        "        X = F.relu(self.fc2(X))\n",
        "        X = F.relu(self.fc3(X))\n",
        "        X = self.fc4(X) # 최종 전결합층 거치기\n",
        "        return F.log_softmax(X, dim=1) # 활성화 함수 : softmax\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=0.001) # Adam 옵티마이저\n",
        "        return optimizer\n",
        "\n",
        "    # 훈련 단계를 정의한 메소드, 손실값을 반환\n",
        "    def training_step(self, train_batch, batch_idx):\n",
        "        X, y = train_batch # 미니 배치\n",
        "        y_hat = self(X) # 예측된 y\n",
        "        loss = F.cross_entropy(y_hat, y) # 손실을 구함 : 교차 엔트로피 오차\n",
        "        pred = y_hat.argmax(dim=1, keepdim=True) # 예측값 : 가장 높은 확률을 가짐\n",
        "        acc = pred.eq(y.view_as(pred)).sum().item() / y.shape[0] # 정확도\n",
        "        self.log(\"train_loss\", loss)\n",
        "        self.log(\"train_acc\", acc)\n",
        "        return loss\n",
        "\n",
        "    # 검증 단계를 정의한 메소드, 알고리즘은 위와 동일\n",
        "    def validation_step(self, val_batch, batch_idx):\n",
        "        X, y = val_batch\n",
        "        y_hat = self(X)\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "        pred = y_hat.argmax(dim=1, keepdim=True)\n",
        "        acc = pred.eq(y.view_as(pred)).sum().item() / y.shape[0]\n",
        "        self.log(\"val_loss\", loss)\n",
        "        self.log(\"val_acc\", acc)\n",
        "\n",
        "    # 테스트 단계를 정의한 메소드, 알고리즘은 위와 동일\n",
        "    def test_step(self, test_batch, batch_idx):\n",
        "        X, y = test_batch\n",
        "        y_hat = self(X)\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "        pred = y_hat.argmax(dim=1, keepdim=True)\n",
        "        acc = pred.eq(y.view_as(pred)).sum().item() / y.shape[0]\n",
        "        self.log(\"test_loss\", loss)\n",
        "        self.log(\"test_acc\", acc)"
      ],
      "metadata": {
        "id": "FJQM53fHkkm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델을 훈련시키고 테스트. if 구문을 아래와 같이 작성하면 해당 스크립트가 포함된 파일을 외부에서 import 해도 if 구문 내 스크립트는 실행되지 않음."
      ],
      "metadata": {
        "id": "BHMi29ewonoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    dataset = ImageDataset(path_label) # 데이터셋 변수 생성, 이미지 파일 경로와 레이블들이 튜플로 묶여있는 리스트 path_label\n",
        "\n",
        "    dataset.setup()  # 데이터를 훈련용과 테스트용으로 분리\n",
        "\n",
        "    train_dataloader = dataset.train_dataloader() # 훈련용\n",
        "    test_dataloader = dataset.test_dataloader() # 테스트용\n",
        "\n",
        "    datamodule = DataModule() # 데이터모듈 객체 생성\n",
        "\n",
        "    datamodule.setup() # 데이터모듈 : 데이터를 훈련용과 테스트용으로 분리\n",
        "\n",
        "    model = ConvolutionalNetwork() # CNN 모델 객체 생성\n",
        "\n",
        "    trainer = pl.Trainer(max_epochs=30) # PyTorch Lightning Trainer : 30 epoch\n",
        "\n",
        "    trainer.fit(model, datamodule) # CNN 모델 훈련 : 30회\n",
        "\n",
        "    datamodule.setup(stage='test') # 데이터모듈 : 테스트 모드로 전환\n",
        "\n",
        "    test_loader = datamodule.test_dataloader() # 데이터모듈 : 테스트용\n",
        "\n",
        "    trainer.test(dataloaders=test_loader) # 테스트용으로 훈련된 모델을 평가"
      ],
      "metadata": {
        "id": "FAJtO47aon9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "최종적으로 테스트셋 평가, 분류 결과를 분석."
      ],
      "metadata": {
        "id": "-32Fom46rp6f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cpu\")   # cuda:0 이면 GPU\n",
        "\n",
        "model.eval()\n",
        "y_true=[]\n",
        "y_pred=[]\n",
        "with torch.no_grad():\n",
        "    for test_data in datamodule.test_dataloader():\n",
        "        test_images, test_labels = test_data[0].to(device), test_data[1].to(device)\n",
        "        pred = model(test_images).argmax(dim=1)\n",
        "        for i in range(len(pred)):\n",
        "            y_true.append(test_labels[i].item())\n",
        "            y_pred.append(pred[i].item())\n",
        "\n",
        "print(classification_report(y_true,y_pred,target_names=class_names,digits=4))"
      ],
      "metadata": {
        "id": "GcggODqkrpn0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}